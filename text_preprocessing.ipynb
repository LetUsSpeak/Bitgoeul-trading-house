{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "text_preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeGQ3Its389_"
      },
      "source": [
        "# 구글드라이브 연동\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)\n",
        "\n",
        "# 구글 드라이브 파일 확인\n",
        "!ls '/gdrive/My Drive/GJ_AI_Colab/프로젝트/data/'\n",
        "\n",
        "# 반복되는 드라이브 경로 변수화\n",
        "drive_path = '/gdrive/My Drive/GJ_AI_Colab/프로젝트/data/'"
      ],
      "id": "XeGQ3Its389_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajaeeoPooA5C"
      },
      "source": [
        "!git clone https://github.com/ssut/py-hanspell.git\n",
        "%cd /content/py-hanspell\n",
        "!python setup.py install"
      ],
      "id": "ajaeeoPooA5C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeRlvSgJoXfW"
      },
      "source": [
        "!pip install pickle5\n",
        "!pip3 install konlpy  # 한국어 형태소 분석을 위해"
      ],
      "id": "eeRlvSgJoXfW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SWsf-JYEmtR"
      },
      "source": [
        "import pandas as pd\n",
        "import pickle5 as pickle\n",
        "import re\n",
        "import nltk\n",
        "\n",
        "from hanspell import spell_checker\n",
        "from konlpy.tag import Okt\n",
        "from nltk.corpus import stopwords"
      ],
      "id": "9SWsf-JYEmtR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTzQCGpSFd21"
      },
      "source": [
        "original_df = pd.read_pickle(drive_path + 'original_data.pkl')"
      ],
      "id": "mTzQCGpSFd21",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fKdl_lABtr9"
      },
      "source": [
        "# 전처리 - okt 이용\n",
        "def okt_preprocessing(name_list):\n",
        "    stopword_list = ['할인', '재구매', '입점', '발송', '순차', '연휴', '황금', '출시', '신제품', '신상', \n",
        "                 '이벤트', '택배', '예약', '출고', '생일', '선물', '답례품', '증정', '당일', '무료', \n",
        "                 '배송', '무배', '주문', '1위', '판매', '폭주', '재입고', '입고']\n",
        "\n",
        "    nltk.download('stopwords')\n",
        "    nltk.download('punkt')\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    okt = Okt()\n",
        "    okt_name = []\n",
        "\n",
        "    for sent in name_list:\n",
        "        sent = re.sub('[^\\w\\s./]', ' ', sent)\n",
        "        for sw in stopword_list:\n",
        "            sent = sent.replace(sw, ' ')  \n",
        "        sent = okt.morphs(sent)\n",
        "        result = ''\n",
        "        for token in sent:\n",
        "            if token not in stop_words:\n",
        "                result += ' ' + token\n",
        "        sent = re.sub('[\\s]+', ' ', result) # 연속된 공백 문자 하나로 변경\n",
        "        sent = sent.strip() # 앞뒤 공백 제거\n",
        "        okt_name.append(sent)\n",
        "    \n",
        "    return okt_name"
      ],
      "id": "5fKdl_lABtr9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfMhoMEaHKtp"
      },
      "source": [
        "rename = okt_preprocessing(original_df['name'])\n",
        "\n",
        "text_preprocessing_df = pd.DataFrame({'id': original_df['id'], 'name': rename, 'label': original_df['label']})\n",
        "text_preprocessing_df.to_pickle(drive_path + 'okt_data.pkl')"
      ],
      "id": "hfMhoMEaHKtp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cac6bc8"
      },
      "source": [
        "# 전처리 - py-hanspell 이용\n",
        "def pyhanspell_preprocessing(name_list):\n",
        "    stopword_list = ['할인', '재구매', '입점', '발송', '순차', '연휴', '황금', '출시', '신제품', '신상', \n",
        "                 '이벤트', '택배', '예약', '출고', '생일', '선물', '답례품', '증정', '당일', '무료', \n",
        "                 '배송', '무배', '주문', '1위', '판매', '폭주', '재입고', '입고']\n",
        "\n",
        "    pyhanspell_name = []\n",
        "\n",
        "    for sent in name_list:\n",
        "        sent = re.sub('[^\\w\\s./]', ' ', sent)\n",
        "        for sw in stopword_list:\n",
        "            sent = sent.replace(sw, ' ')\n",
        "        sent = re.sub('[\\s]+', ' ',sent) # 연속된 공백 문자 하나로 변경\n",
        "        sent = sent.strip() # 앞뒤 공백 제거\n",
        "        spelled_sent = spell_checker.check(sent)\n",
        "        checked_sent = spelled_sent.checked\n",
        "        pyhanspell_name.append(checked_sent)\n",
        "\n",
        "    return pyhanspell_name"
      ],
      "id": "4cac6bc8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcdzUl4BN8Qx"
      },
      "source": [
        "rename = pyhanspell_preprocessing(original_df['name'])\n",
        "\n",
        "text_preprocessing_df = pd.DataFrame({'id': original_df['id'], 'name': rename, 'label': original_df['label']})\n",
        "text_preprocessing_df.to_pickle(drive_path + 'pyhanspell_data.pkl')"
      ],
      "id": "VcdzUl4BN8Qx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ou1QdkoHET5"
      },
      "source": [
        ""
      ],
      "id": "9Ou1QdkoHET5",
      "execution_count": null,
      "outputs": []
    }
  ]
}